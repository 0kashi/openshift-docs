// Module included in the following assemblies:
//
// * machine_management/applying-autoscaling.adoc

[id="cluster-autoscaler-cr_{context}"]
= ClusterAutoscaler resource definition

This `ClusterAutoscaler` resource definition shows the parameters and sample
values for the ClusterAutoscaler.


[source,yaml]
----
apiVersion: "autoscaling.openshift.io/v1"
kind: "ClusterAutoscaler"
metadata:
  name: "default"
spec:
  podPriorityThreshold: -10 <1>
  resourceLimits:
    maxNodesTotal: 24 <2>
    cores:
      min: 8 <3>
      max: 128 <4>
    memory:
      min: 4 <5>
      max: 256 <6>
    gpus:
      - type: nvidia.com/gpu <7>
        min: 0 <8>
        max: 16 <9>
      - type: amd.com/gpu <7>
        min: 0 <8>
        max: 4 <9>
  scaleDown:
    enabled: true <10>
    delayAfterAdd: 10s <11>
    delayAfterDelete: 10s <12>
    delayAfterFailure: 10s <13>
    unneededTime: 10s <14>
----
<1> Specify the priority that a pod must exceed to cause the ClusterAutoscaler
to deploy additional nodes. Enter a 32-bit integer value. The
`podPriorityThreshold` value is compared to the value of the `PriorityClass` that
you assign to each pod.
<2> Specify the maximum number of nodes to deploy.
<3> Specify the minimum number of cores to deploy.
<4> Specify the maximum number of cores to deploy.
<5> Specify the minimum amount of memory, in GiB, per node.
<6> Specify the maximum amount of memory, in GiB, per node.
<7> Specify the type of GPU node to deploy. Only `nvidia.com/gpu` and `amd.com/gpu`
are valid types.
<8> Specify the minimum number of GPUs to deploy.
<9> Specify the maximum number of GPUs to deploy.
<10> Specify whether the ClusterAutoscaler can remove unnecessary nodes.
<11> Specify the period, in seconds, to wait before deploying another node.
<12> Specify the period, in seconds, to wait before deleting another node.
<13> Specify the period, in seconds, to wait to deploy another node if the
current deployment fails.
<14> Specify the period, in seconds, before an unnecessary node is deleted.
