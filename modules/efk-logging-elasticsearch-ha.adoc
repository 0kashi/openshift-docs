// Module included in the following assemblies:
//
// * logging/efk-logging-elasticsearch.adoc

[id='efk-logging-elasticsearch-ha-{context}']
= Configuring Elasticsearch replication policy

You can define how Elasticsearch shards are replicated across data nodes in the cluster:

* *FullRedundancy*. Elasticsearch fully replicates the primary shards for each index 
to every data node. This provides the highest safety, but at the cost of the highest amount of disk required and the poorest performance.
* *MultipleRedundancy*. Elasticsearch fully replicates the primary shards for each index to half of the data nodes.
This provides a good tradeoff between safety and performance.
* *SingleRedundancy*. Elasticsearch makes one copy of the primary shards for each index. 
Logs are always available and recoverable as long as at least two data nodes exist.
Better performance than MultipleRedundancy, when using 5 or more nodes.  You cannot 
apply this policy on deployments of single Elasticsearch node.
* *ZeroRedundancy*. Elasticsearch does not make copies of the primary shards. 
Logs might be unavailable or lost in the event a node is down or fails.
Use this mode when you are more concerned with performance than safety, or have 
implemented your own disk/PVC backup/restore strategy.


.Prerequisite

* Cluster logging and Elasticsearch must be installed.

* Set cluster logging to the unmanaged state.

* If needed, get the name of the Cluster Logging Custom Resource from the `openshift-logging` project:
+
----
$ oc get ClusterLogging
NAME       AGE
instance   112m
----

.Procedure

Edit the Cluster Logging Custom Resource (CR) from the `openshift-logging` project: 

[source,yaml]
----
apiVersion: "logging.openshift.io/v1alpha1"
kind: "ClusterLogging"
metadata:
  name: "clusterlogging"

....

spec:
  logStore:
    type: "elasticsearch"
    elasticsearch: 
      redundancyPolicy: "SingleRedundancy" <1>
----
<1> Specify a redundancy policy for the shards.

