// Module included in the following assemblies:
//
// * nodes/nodes-scheduler-taints-tolerations.adoc

[id="nodes-scheduler-taints-tolerations-about-{context}"]
= Understanding taints and tolerations in {product-title}

A _taint_ allows a node to refuse pod to be scheduled unless that pod has a matching _toleration_.

You apply taints to a node through the node specification (`NodeSpec`) and apply tolerations to a pod through the pod specification (`PodSpec`). A taint on a node instructs the node to repel all pods that do not tolerate the taint.

Taints and tolerations consist of a key, value, and effect. An operator allows you to leave one of these parameters empty.

[id="taint-components-table-{context}"]
.Taint and toleration components
[cols="3a,8a",options="header"]
|===

|Parameter |Description

|`key`
|The `key` is any string, up to 253 characters. The key must begin with a letter or number, and may contain letters, numbers, hyphens, dots, and underscores.

|`value`
| The `value` is any string, up to 63 characters. The value must begin with a letter or number, and may contain letters, numbers, hyphens, dots, and underscores.

|`effect`

|The effect is one of the following:
[frame=none]
[cols="2a,3a"]
!====
!`NoSchedule`
!* New pods that do not match the taint are not scheduled onto that node.
* Existing pods on the node remain.
!`PreferNoSchedule`
!* New pods that do not match the taint might be scheduled onto that node, but the scheduler tries not to.
* Existing pods on the node remain.
!`NoExecute`
!* New pods that do not match the taint cannot be scheduled onto that node.
* Existing pods on the node that do not have a matching toleration  are removed.
!====

|`operator`
|[frame=none]
[cols="2,3"]
!====
!`Equal`
!The `key`/`value`/`effect` parameters must match. This is the default.
!`Exists`
!The `key`/`effect` parameters must match. You must leave a blank `value` parameter, which matches any.
!====

|===

A toleration matches a taint:

* If the `operator` parameter is set to `Equal`:
** the `key` parameters are the same;
** the `value` parameters are the same;
** the `effect` parameters are the same.

* If the `operator` parameter is set to `Exists`:
** the `key` parameters are the same;
** the `effect` parameters are the same.

[id="nodes-scheduler-taints-tolerations-about-seconds-{context}"]
== Understanding how to use toleration seconds to delay pod evictions

You can specify how long a pod can remain bound to a node before being evicted by specifying the `tolerationSeconds` parameter in the pod specification. If a taint with the `NoExecute` effect is added to a node, any pods that do not tolerate the taint are evicted immediately (pods that do tolerate the taint are not evicted). However, if a pod that to be evicted has the `tolerationSeconds` parameter, the pod is not evicted until that time period expires.

For example:
[source, yaml]
----
tolerations:
- key: "key1"
  operator: "Equal"
  value: "value1"
  effect: "NoExecute"
  tolerationSeconds: 3600
----

Here, if this pod is running but does not have a matching taint, the pod stays bound to the node for 3,600 seconds and then be evicted. If the taint is removed before that time, the pod is not evicted.

[id="nodes-scheduler-taints-tolerations-about-multiple-{context}"]
== Understanding how to use multiple taints

You can put multiple taints on the same node and multiple tolerations on the same pod. {product-title} processes multiple taints and tolerations as follows:

. Process the taints for which the pod has a matching toleration.
. The remaining unmatched taints have the indicated effects on the pod:
+
* If there is at least one unmatched taint with effect `NoSchedule`, {product-title} cannot schedule a pod onto that node.
* If there is no unmatched taint with effect `NoSchedule` but there is at least one unmatched taint with effect `PreferNoSchedule`, {product-title} tries to not schedule the pod onto the node.
* If there is at least one unmatched taint with effect `NoExecute`, {product-title} evicts the pod from the node (if it is already running on the node), or the pod is not scheduled onto the node (if it is not yet running on the node).
+
** Pods that do not tolerate the taint are evicted immediately.
+
** Pods that tolerate the taint without specifying `tolerationSeconds` in their toleration specification remain bound forever.
+
** Pods that tolerate the taint with a specified `tolerationSeconds` remain bound for the specified amount of time.

For example:

* The node has the following taints:
+
----
$ oc adm taint nodes node1 key1=value1:NoSchedule
$ oc adm taint nodes node1 key1=value1:NoExecute
$ oc adm taint nodes node1 key2=value2:NoSchedule
----

* The pod has the following tolerations:
+
[source, yaml]
----
tolerations:
- key: "key1"
  operator: "Equal"
  value: "value1"
  effect: "NoSchedule"
- key: "key1"
  operator: "Equal"
  value: "value1"
  effect: "NoExecute"
----

In this case, the pod cannot be scheduled onto the node, because there is no toleration matching the third taint. The pod continues running if it is already running on the node when the taint is added, because the third taint is the only
one of the three that is not tolerated by the pod.

[id="nodes-scheduler-taints-tolerations-about-prevent-{context}"]
== Preventing pod eviction for node problems

{product-title} can be configured to represent *node unreachable* and *node not ready* conditions as taints.  This allows per-pod specification of how long to remain bound to a node that becomes unreachable or not ready, rather than using the default of five minutes.

The Taint-Based Evictions feature is enabled by default. The taints are automatically added by the node controller and the normal logic for evicting pods from `Ready` nodes is disabled.

* If a node enters a not ready state, the `node.kubernetes.io/not-ready:NoExecute`  taint is added and pods cannot be scheduled on the node. Existing pods remain for the toleration seconds period.
* If a node enters a not reachable state, the `node.kubernetes.io/unreachable:NoExecute` taint is added and pods cannot be scheduled on the node. Existing pods remain for the toleration seconds period.

This feature, in combination with `tolerationSeconds`, allows a pod to specify how long it should stay bound to a node that has one or both of these problems.


[id="nodes-scheduler-taints-tolerations-about-taintNodesByCondition-{context}"]
== Taint Nodes By Condition


{product-title} has TaintNodesByCondition feature enabled by default, so node lifecycle controller automatically creates taints corresponding to Node conditions like memory pressure, disk pressure. Similarly the scheduler does not check Node conditions; instead the scheduler checks taints. This assures that Node conditions don’t affect what’s scheduled onto the Node. The user can choose to ignore some of the Node’s problems (represented as Node conditions) by adding appropriate Pod tolerations. Note that TaintNodesByCondition only taints nodes with NoSchedule effect.

The DaemonSet controller automatically adds the following NoSchedule tolerations to all daemons, to prevent DaemonSets from breaking.

    node.kubernetes.io/memory-pressure
    node.kubernetes.io/disk-pressure
    node.kubernetes.io/out-of-disk (only for critical pods)
    node.kubernetes.io/unschedulable (1.10 or later)
    node.kubernetes.io/network-unavailable (host network only)

Adding these tolerations ensures backward compatibility. You can also add arbitrary tolerations to DaemonSets


[id="nodes-scheduler-taints-tolerations-about-taintBasedEvictions-{context}"]
== Taint Based Evictions

Earlier we mentioned the NoExecute taint effect, which affects pods that are already running on the node as follows

    pods that do not tolerate the taint are evicted immediately
    pods that tolerate the taint without specifying tolerationSeconds in their toleration specification remain bound forever
    pods that tolerate the taint with a specified tolerationSeconds remain bound for the specified amount of time

The node controller automatically taints a node when certain condition is true. The following taints are built in:

    node.kubernetes.io/not-ready: Node is not ready. This corresponds to the NodeCondition Ready being “False”.
    node.kubernetes.io/unreachable: Node is unreachable from the node controller. This corresponds to the NodeCondition Ready being “Unknown”.
    node.kubernetes.io/out-of-disk: Node becomes out of disk.
    node.kubernetes.io/memory-pressure: Node has memory pressure.
    node.kubernetes.io/disk-pressure: Node has disk pressure.
    node.kubernetes.io/network-unavailable: Node’s network is unavailable.
    node.kubernetes.io/unschedulable: Node is unschedulable.
    node.cloudprovider.kubernetes.io/uninitialized: When the kubelet is started with “external” cloud provider, this taint is set on a node to mark it as unusable. After a controller from the cloud-controller-manager initializes this node, the kubelet removes this taint.

{product-title} has TaintBasedEvictions feature enabled by default, hence the taints are automatically added by the NodeController (or kubelet) and the normal logic for evicting pods from nodes based on the Ready NodeCondition is disabled.

    Note: To maintain the existing rate limiting behavior of pod evictions due to node problems, the system actually adds the taints in a rate-limited way. This prevents massive pod evictions in scenarios such as the master becoming partitioned from the nodes.

This feature, in combination with tolerationSeconds, allows a pod to specify how long it should stay bound to a node that has one or both of these problems.

For example, an application with a lot of local state might want to stay bound to node for a long time in the event of network partition, in the hope that the partition will recover and thus the pod eviction can be avoided. The toleration the pod would use in that case would look like

tolerations:
- key: "node.kubernetes.io/unreachable"
  operator: "Exists"
  effect: "NoExecute"
  tolerationSeconds: 6000

Note that {product-title}  automatically adds a toleration for node.kubernetes.io/not-ready with tolerationSeconds=300 unless the pod configuration provided by the user already has a toleration for node.kubernetes.io/not-ready. Likewise it adds a toleration for node.kubernetes.io/unreachable with tolerationSeconds=300 unless the pod configuration provided by the user already has a toleration for node.kubernetes.io/unreachable.

These automatically-added tolerations ensure that the default pod behavior of remaining bound for 5 minutes after one of these problems is detected is maintained. The two default tolerations are added by the DefaultTolerationSeconds admission controller.

DaemonSet pods are created with NoExecute tolerations for the following taints with no tolerationSeconds:

    node.kubernetes.io/unreachable
    node.kubernetes.io/not-ready

This ensures that DaemonSet pods are never evicted due to these problems.


[NOTE]
====
DaemonSet pods are created with `NoExecute` tolerations for `node.kubernetes.io/unreachable` and `node.kubernetes.io/not-ready`
with no `tolerationSeconds` to ensure that DaemonSet pods are never evicted due to these problems, even when the Default Toleration Seconds feature is disabled.
====
