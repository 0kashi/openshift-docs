// Module included in the following assemblies:
//
// * nodes/nodes-cluster-overcommit.adoc

[id='nodes-cluster-overcommit-node-memory_{context}']

= Reserving memory across quality of service tiers

You can use the `qos-reserved` parameter to specify a percentage of memory to be reserved
by a pod in a particular QoS level. This feature attempts to reserve requested resources to exclude pods
from lower OoS classes from using resources requested by pods in higher QoS classes.

By reserving resources for higher QOS levels, pods that don't have resource limits are prevented from encroaching on the resources
requested by pods at higher QoS levels.

.Procedure

To configure the `qos-reserved` parameter, edit the appropriate node configuration map.

----
kubeletArguments:
  cgroups-per-qos:
  - true
  cgroup-driver:
  - 'systemd'
  cgroup-root:
  - '/'
  qos-reserved: <1>
  - 'memory=50%'
----
<1> Specifies how pod resource requests are reserved at the QoS level.
{product-title} uses the `qos-reserved` parameter as follows:
- A value of `qos-reserved=memory=100%` will prevent the `Burstable` and `BestEffort` QOS classes from consuming memory
that was requested by a higher QoS class. This increases the risk of inducing OOM
on `BestEffort` and `Burstable` workloads in favor of increasing memory resource guarantees
for `Guaranteed` and `Burstable` workloads.
- A value of `qos-reserved=memory=50%` will allow the `Burstable` and `BestEffort` QOS classes
to consume half of the memory requested by a higher QoS class.
- A value of `qos-reserved=memory=0%`
will allow a `Burstable` and `BestEffort` QoS classes to consume up to the full node
allocatable amount if available, but increases the risk that a `Guaranteed` workload
will not have access to requested memory. This condition effectively disables this feature.

