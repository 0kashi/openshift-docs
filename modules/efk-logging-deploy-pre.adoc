// Module included in the following assemblies:
//
// * logging/efk-logging-deploy.adoc

[id='efk-logging-deploy-pre_{context}']
= Prerequisites for deploying the EFK stack

Before deploying the EFK stack into {product-title} perform the following tasks:

[procedure]

* Be familiar with the following:
+
** An Ansible playbook is available to deploy and upgrade aggregated logging. You
should familiarize yourself with the {product-title} installation process. The installation process
includes information for preparing to use Ansible and using the Ansible inventory file to configure
various areas of the EFK stack.
+
** Review the *Storage Considerations for EFK Logging and {product-title}* to determine how best to configure your deployment.

* Make sure your environment meets the following requirements:
+
** Ensure that you have deployed a router for the cluster.
+
** Ensure that you have the necessary persistent storage for Elasticsearch. Note that each Elasticsearch replica
requires its own storage volume. 

* Specify a node selector
+
In order for the logging pods to spread evenly across your cluster, an empty
node selector should be used.
+
----
$ oc adm new-project logging --node-selector=""
----

* Choose a project. 
+
Once deployed, the EFK stack collects logs for every
project within your {product-title} cluster. But the stack requires a dedicated project, by default *openshift-logging*.
The Ansible playbook creates the project for you. You only need to create a project if you want
to specify a node-selector on it. 
+
----
$ oc adm new-project logging --node-selector=""
$ oc project logging
----
+
[NOTE]
====
Specifying an empty node selector on the project is recommended, as Fluentd should be deployed
throughout the cluster and any selector would restrict where it is
deployed. To control component placement, specify node selectors per component to
be applied to their deployment configurations.
====
