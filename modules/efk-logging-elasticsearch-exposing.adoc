// Module included in the following assemblies:
//
// * logging/efk-logging-elasticsearch.adoc

[id='efk-logging-elasticsearch-exposing_{context}']
= Exposing Elasticsearch as a route

By default, Elasticsearch deployed with cluster logging is not
accessible from outside the logging cluster. You can enable a route for external
access to Elasticsearch for those tools that want to access its data.

You have access to Elasticsearch using your {product-title} token, and
you can provide the external Elasticsearch and Elasticsearch Ops
hostnames when creating the server certificate (similar to Kibana).

.Prerequisite

Set cluster logging to the unmanaged state.

.Procedure

. Use the following command to get name of the ElasticSearch pod:
+
----
ESPOD=$( oc get pods -l component=elasticsearch -o name | sed -e "s/pod\///" )
----

. Use the following command to extract CA certificate to a file:
+
----
oc exec $ESPOD -- cat /etc/openshift/elasticsearch/secret/admin-ca > ./admin-ca
----

. Create the route object for the ElasticSearch service as an yaml file:
+
----
apiVersion: route.openshift.io/v1
kind: Route
metadata:
  name: elasticsearch
  namespace: openshift-logging
spec:
  host:
  to:
    kind: Service
    name: elasticsearch
  tls:
    termination: reencrypt
    caCertificate: |-
----

. Use the following commands to add the CA certificate to the object YAML file:
+
----
cat ./admin-ca | sed -e "s/^/      /" >> my_es_route.yaml
echo "    destinationCACertificate: |-" >> my_es_route.yaml
cat ./admin-ca | sed -e "s/^/      /" >> my_es_route.yaml
----

. Use the following command to create the service:
+
----
oc create -f my_es_route.yaml
----

. Check the ElasticSearch service is exposed:
+
----
curl --silent --insecure -H "Authorization: Bearer $( oc whoami -t )" "https://$( oc get route elasticsearch -o jsonpath='{.spec.host}' ):443/.operations.*/_search" | jq
----
