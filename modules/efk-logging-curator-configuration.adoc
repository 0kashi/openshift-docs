// Module included in the following assemblies:
//
// * logging/efk-logging-curator.adoc

[id='efk-logging-curator-configuration_{context}']
= Modifying the Curator configuration

You can configure your ops and non-ops Curator instances using the the `logging-curator` configuration map
created by the Cluster Logging Operator installation.

You can edit or replace this ConfigMap to reconfigure Curator. 

[NOTE]
====
Any `.operations` configurations are in the same location as your application logs configurations.
====

.Prerequisite

Set cluster logging to the unmanaged state.

.Procedure

. To configure Curator, edit the `logging-curator` configuration map:
+
[source,bash]
----
$ oc edit configmap/logging-curator
----
+
[source,yaml]
----
client:
  hosts:
    - 127.0.0.1 <1>
  port: 9200  <2>
  url_prefix: <3>
  use_ssl: False <4>
  certificate: <5>
  client_cert: <6>
  client_key: <7>
  ssl_no_validate: False <8>
  http_auth: <9>
  timeout: 30  <10>
  master_only: False <11>

logging:
  loglevel: INFO
  logfile:
  logformat: default
  blacklist: ['elasticsearch', 'urllib3']
----
<1> Specify the hosts where Curator will run.
<2> Specify the port number of the Elasticsearch cluster, by default 9200.
<3> Optionally, specify a url_prefix to the appropriate value, if needed. For example, if you connect to your Elasticsearch cluster through a proxy and need a URL as opposed to http://localhost:9200. 
<4> Optionally, specify `True`, 'False` or left empty. If access to your Elasticsearch instance is protected by SSL encryption, set to `True`.
<5> Optionally, specify a file path to your CA certificate, in single quotes, to validate the SSL certificate used by Elasticsearch or leave empty.
<6> Optionally, specify a file path to an SSL client cert file to authenticate to Elasticsearch. The file may contain both an SSL client certificate and an SSL key, in which case client_key is not used. If specifying client_cert, and the file specified does not also contain the key, use client_key to specify the file containing the SSL key. The file must be in PEM format, and the key part, if used, must be an unencrypted key in PEM format as well. Leave empty if not using a SSL client cert.
<7> Optionally, specify an SSL client key file to authenticate to Elasticsearch. If using client_cert and the file specified does not also contain the key, use client_key to specify the file containing the SSL key. The key file must be an unencrypted key in PEM format. Leave empty if not using a SSL client cert.
<8> Set to `True` to disable SSL certificate verification. Setting ssl_no_validate to True will likely result in a warning message that your SSL certificates are not trusted. This is expected behavior.
<9> Optionally, specify authentication credentials, such as `user:pass`, or leave empty. 
<10> Optionally, specify the default client connection timeout value, by default 30 seconds.
<11> Optionally, set to `True` to run Curator on the master node only.
+
For more information on these parameters, see the link:https://www.elastic.co/guide/en/elasticsearch/client/curator/5.2/configfile.html[Elastic Search curator documentation].

. Set the minimum acceptable log severity to display.
+
----
logging:
  loglevel: INFO <1>
  logfile:
  logformat: default
  blacklist: ['elasticsearch', 'urllib3']
----
+
Specify the log level:
+
* *CRITICAL*. Curator displays only critical messages.
* *ERROR*. Curator displays only  error and critical messages.
* *WARNING*. Curator displays only  error, warning, and critical messages.
* *INFO*. Curator displays only informational, error, warning, and critical messages.
* *DEBUG*. Curator displays only debug messages, in addition to all of the above. 
+
The default value is INFO.

[NOTE]
====
Cluster Logging uses the {product-title} custom environment variable `CURATOR_SCRIPT_LOG_LEVEL` in {product-title} wrapper scripts (run.sh and convert.py).
The environment variable takes the same values as `CURATOR_LOG_LEVEL` for script debugging, as needed.
====

[[efk-logging-curator-configuration-cronjob]]
== Configuring Curator using a CronJob

You can alternatively create, configure, and run Curator using a CronJob. The next scheduled job uses this configuration.

[source,bash]
----
oc create job --from=cronjob/logging-curator <job_name>
----

You can use this command for debugging Curator. For example, if curator is in failed state, but the log messages do not provide a reason, you could
increase the log level and run the cronjob with this command, instead of waiting for another scheduled run of the cron job.

* For scripted deployments, copy the configuration file that was created by the
installer and create your new {product-title} custom configuration:
+
[source,bash]
----
$ oc extract configmap/logging-curator --keys=curator5.yaml,config.yaml --to=/my/config
  edit /my/config/curator5.yaml
  edit /my/config/config.yaml
$ oc delete configmap logging-curator ; sleep 1
$ oc create configmap logging-curator \
    --from-file=curator5.yaml=/my/config/curator5.yaml \
    --from-file=config.yaml=/my/config/config.yaml \
    ; sleep 1
----

* Alternatively, if you are using the *actions file*:
+
[source,bash]
----
$ oc extract configmap/logging-curator --keys=curator5.yaml,actions.yaml --to=/my/config
  edit /my/config/curator5.yaml
  edit /my/config/actions.yaml
$ oc delete configmap logging-curator ; sleep 1
$ oc create configmap logging-curator \
    --from-file=curator5.yaml=/my/config/curator5.yaml \
    --from-file=actions.yaml=/my/config/actions.yaml \
    ; sleep 1
----

Use the following commands to control the CronJob:

* Suspend a cronjob:
+
[source,bash]
----
$ oc patch cronjob logging-curator -p '{"spec":{"suspend":true}}'
----

* Resume a CronJob:
+
[source,bash]
----
oc patch cronjob logging-curator -p '{"spec":{"suspend":false}}
----

* Change a cronjob schedule:
+
[source,bash]
----
oc patch cronjob logging-curator -p '{"spec":{"schedule":"0 0 * * *"}}' <1>
----
<1> The `schedule` option accepts schedules in link:https://en.wikipedia.org/wiki/Cron[cron format].
