// Module included in the following assemblies:
//
// * assembly/networking/routing-from-edge-load-balancer.adoc

[id="nw-establishing-a-tunnel-using-a-ramp-node-{context}"]
= Establishing a tunnel using a ramp node

In some cases, the previous solution is not possible. For example, an `F5
BIG-IP®` host cannot run an {product-title} node instance or the {product-title}
SDN because `F5®` uses a custom, incompatible Linux kernel and distribution.

Instead, to enable `F5 BIG-IP®` to reach pods, you can choose an existing node
within the cluster network as a ramp node and establish a tunnel between the
`F5 BIG-IP®` host and the designated ramp node. Because it is otherwise an
ordinary {product-title} node, the ramp node has the necessary configuration to
route traffic to any pod on any node in the cluster network. The ramp node thus
assumes the role of a gateway through which the `F5 BIG-IP®` host has access to
the entire cluster network.

.Procedure

Following is an example of establishing an `ipip` tunnel between an `F5 BIG-IP®`
host and a designated ramp node.

*On the `F5 BIG-IP®` host:*

. Set the following variables:
+
----
# F5_IP=10.3.89.66 <1>
# RAMP_IP=10.3.89.89 <1>
# TUNNEL_IP1=10.3.91.216 <2>
# CLUSTER_NETWORK=10.128.0.0/14 <3>
----
<1> The `F5_IP` and `RAMP_IP` variables refer to the `F5 BIG-IP®` host's and
the ramp node's IP addresses, respectively, on a shared, internal network.
<2> An arbitrary, non-conflicting IP address for the `F5®` host's end of the
`ipip` tunnel.
<3> The overlay network CIDR range that the OpenShift SDN uses to assign addresses to pods.

. Delete any old route, self, tunnel and SNAT pool:
+
----
# tmsh delete net route $CLUSTER_NETWORK || true
# tmsh delete net self SDN || true
# tmsh delete net tunnels tunnel SDN || true
# tmsh delete ltm snatpool SDN_snatpool || true
----

. Create the new tunnel, self, route and SNAT pool and use the SNAT pool
  in the virtual servers:
+
[options="nowrap"]
----
# tmsh create net tunnels tunnel SDN \
    \{ description "OpenShift SDN" local-address \
    $F5_IP profile ipip remote-address $RAMP_IP \}
# tmsh create net self SDN \{ address \
    ${TUNNEL_IP1}/24 allow-service all vlan SDN \}
# tmsh create net route $CLUSTER_NETWORK interface SDN
# tmsh create ltm snatpool SDN_snatpool members add { $TUNNEL_IP1 }
# tmsh modify ltm virtual  ose-vserver source-address-translation { type snat pool SDN_snatpool }
# tmsh modify ltm virtual  https-ose-vserver source-address-translation { type snat pool SDN_snatpool }
----

*On the ramp node:*

[NOTE]
====
The following creates a configuration that is not persistent, meaning that when
the ramp node or the `openvswitch` service is restarted, the settings disappear.
====

. Set the following variables:
+
----
# F5_IP=10.3.89.66
# TUNNEL_IP1=10.3.91.216
# TUNNEL_IP2=10.3.91.217 <1>
# CLUSTER_NETWORK=10.128.0.0/14 <2>
----
<1> A second, arbitrary IP address for the ramp node's end of the `ipip`
tunnel.
<2> The overlay network CIDR range that the OpenShift SDN uses to assign addresses to pods.

. Delete any old tunnel:
+
----
# ip tunnel del tun1 || true
----

. Create the `ipip` tunnel on the ramp node, using a suitable L2-connected
interface (e.g., `eth0`):
+
[options="nowrap"]
----
# ip tunnel add tun1 mode ipip \
    remote $F5_IP dev eth0
# ip addr add $TUNNEL_IP2 dev tun1
# ip link set tun1 up
# ip route add $TUNNEL_IP1 dev tun1
# ping -c 5 $TUNNEL_IP1
----

. SNAT the tunnel IP with an unused IP from the SDN subnet:
+
[options="nowrap"]
----
# source /run/openshift-sdn/config.env
# tap1=$(ip -o -4 addr list tun0 | awk '{print $4}' | cut -d/ -f1 | head -n 1)
# subaddr=$(echo ${OPENSHIFT_SDN_TAP1_ADDR:-"$tap1"} | cut -d "." -f 1,2,3)
# export RAMP_SDN_IP=${subaddr}.254
----

. Assign this `RAMP_SDN_IP` as an additional address to `tun0` (the local SDN's
gateway):
+
----
# ip addr add ${RAMP_SDN_IP} dev tun0
----

. Modify the OVS rules for SNAT:
+
[options="nowrap"]
----
# ipflowopts="cookie=0x999,ip"
# arpflowopts="cookie=0x999, table=0, arp"
#
# ovs-ofctl -O OpenFlow13 add-flow br0 \
    "${ipflowopts},nw_src=${TUNNEL_IP1},actions=mod_nw_src:${RAMP_SDN_IP},resubmit(,0)"
# ovs-ofctl -O OpenFlow13 add-flow br0 \
    "${ipflowopts},nw_dst=${RAMP_SDN_IP},actions=mod_nw_dst:${TUNNEL_IP1},resubmit(,0)"
# ovs-ofctl -O OpenFlow13 add-flow br0 \
    "${arpflowopts}, arp_tpa=${RAMP_SDN_IP}, actions=output:2"
# ovs-ofctl -O OpenFlow13 add-flow br0 \
    "${arpflowopts}, priority=200, in_port=2, arp_spa=${RAMP_SDN_IP}, arp_tpa=${CLUSTER_NETWORK}, actions=goto_table:30"
# ovs-ofctl -O OpenFlow13 add-flow br0 \
    "arp, table=5, priority=300, arp_tpa=${RAMP_SDN_IP}, actions=output:2"
# ovs-ofctl -O OpenFlow13 add-flow br0 \
    "ip,table=5,priority=300,nw_dst=${RAMP_SDN_IP},actions=output:2"
# ovs-ofctl -O OpenFlow13 add-flow br0 "${ipflowopts},nw_dst=${TUNNEL_IP1},actions=output:2"
----

. Optionally, if you do not plan on configuring the ramp node to be
highly available, mark the ramp node as unschedulable. Skip this step if you do
plan to follow the next section and plan on creating a highly available ramp
node.
+
[options="nowrap"]
----
$ oc adm manage-node <ramp_node_hostname> --schedulable=false
----


[NOTE]
====
F5 router plug-in integrates with `F5 BIG-IP®`.
====
