// Module included in the following assemblies:
//
// * nodes/nodes-nodes-modifying.adoc

[id='nodes-nodes-moifying-maximum_{context}']
= Understanding how to set maximum pods per node

////
The following section is included in the Scaling and Performance Guide.
////

[NOTE]
====
See the Cluster Limits page in the Scaling and Performance guide for the maximum supported limits for each version of
{product-title}.
====

In the *_/etc/origin/node/node-config.yaml_* file, two parameters control the
maximum number of pods that can be scheduled to a node: `pods-per-core` and
`max-pods`. When both options are in use, the lower of the two limits the number
of pods on a node. Exceeding these values can result in:

* Increased CPU utilization on both {product-title} and Docker.
* Slow pod scheduling.
* Potential out-of-memory scenarios (depends on the amount of memory in the node).
* Exhausting the pool of IP addresses.
* Resource overcommitting, leading to poor user application performance.

[NOTE]
====
In Kubernetes, a pod that is holding a single container actually uses two
containers. The second container is used to set up networking prior to the
actual container starting. Therefore, a system running 10 pods will actually
have 20 containers running.
====

`pods-per-core` sets the number of pods the node can run based on the number of
processor cores on the node. For example, if `pods-per-core` is set to `10` on
a node with 4 processor cores, the maximum number of pods allowed on the node
will be 40.

----
kubeletArguments:
  pods-per-core:
    - "10"
----

[NOTE]
====
Setting `pods-per-core` to 0 disables this limit.
====

`max-pods` sets the number of pods the node can run to a fixed value, regardless
of the properties of the node.

----
kubeletArguments:
  max-pods:
    - "250"
----

Using the above example, the default value for `pods-per-core` is `10` and the
default value for `max-pods` is `250`. This means that unless the node has 25
cores or more, by default, `pods-per-core` will be the limiting factor.

