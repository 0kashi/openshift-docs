// Module included in the following assemblies:
//
// * logging/efk-logging-elasticsearch.adoc

[id='efk-logging-elasticsearch-scaling-{context}']
= Changing the number of Elasticsearch nodes

If you need to scale up the number of Elasticsearch nodes your cluster uses,
you need to create a new deployment configuration for each Elasticsearch cluster
node.

You cannot scale up an existing Elasticsearch deployment configuration.
This is due to the nature of persistent volumes and how Elasticsearch is
configured to store its data and recover the cluster.

Assuming you have supplied persistent storage for the deployment, this should not be
disruptive.

[NOTE]
====
Resizing an Elasticsearch cluster using the logging playbook is only possible when
the new `openshift_logging_es_cluster_size` value is higher than the current number
of Elasticsearch nodes (scaled up) in the cluster.
====

If you do not wish to reinstall, for instance because you have made
customizations that you would like to preserve, then it is possible to add new
Elasticsearch deployment configurations to the cluster using a template supplied
by the deployer. This requires a more complicated procedure however.


.Procedure

. Create a new deployment configuration for each new node.

. Edit the Ansible hosts file to add the new nodes:
+
----
openshift_logging_es_cluster_size=<number-of-nodes>
----

. Run the logging playbook.
+
----
$ ansible-playbook [-i </path/to/inventory>] \
    /usr/share/ansible/openshift-ansible/playbooks/openshift-logging/config.yml
---

