// Module included in the following assemblies:
//
// * logging/efk-logging-elasticsearch.adoc

[id="efk-logging-elasticsearch-exposing-{context}"]
= Exposing Elasticsearch as a route

By default, Elasticsearch deployed with cluster logging is not
accessible from outside the logging cluster. You can enable a route with re-encryption termination 
for external access to Elasticsearch for those tools that want to access its data.

Internally, you can access Elasticsearch using your {product-title} token, and
you can provide the external Elasticsearch and Elasticsearch Ops
hostnames using the server certificate (similar to Kibana).

* The request must contain three HTTP headers:
+
----
Authorization: Bearer $token
X-Proxy-Remote-User: $username
X-Forwarded-For: $ip_address
----

.Prerequisites

* Cluster logging and Elasticsearch must be installed.

* Set cluster logging to the unmanaged state.

* You must have access to the project in order to be able to access to the logs. For example:
+
----
$ oc login <user1>
$ oc new-project <user1project>
$ oc new-app <httpd-example>
----

.Procedure

. Use the following command to set name of the Elasticsearch pod in a variable for use in a cURL command:
+
----
ESPOD=$( oc get pods -l component=elasticsearch -o name | sed -e "s/pod\///" )
----

. Use the following command to extract the CA certificate from Elasticsearch and write to the *_admin-ca_* file:
+
----
$ oc extract secret/elasticsearch --to=. --keys=admin-ca

admin-ca
----

. Create the route for the Elasticsearch service as a YAML file:
+
.. Create a YAML file with the following:
+
----
apiVersion: route.openshift.io/v1
kind: Route
metadata:
  name: elasticsearch
  namespace: openshift-logging
spec:
  host: 
  to:
    kind: Service
    name: elasticsearch
  tls:
    termination: reencrypt
    destinationCACertificate: <1>
----
<1> Add the Elasticsearch CA ceritifcate or use the command in the next step. You do not need to set the `spec.tls.key`, `spec.tls.certificate` and `spec.tls.caCertificate` parameters
required by some reencrypt routes.

.. Run the following command to add the Elasticsearch CA certificate to the route YAML you created:
+
----
cat ./admin-ca | sed -e "s/^/      /" >> <file-name>.yaml
----  

.. Run the following command to create the route:
+
----
$ oc create -f <file-name>.yaml

route.route.openshift.io/elasticsearch created
----
+
//For an example reencrypt route object, see Re-encryption Termination.
//+
//This line ^^ will be linked when the topic is available.

. Check that the Elasticsearch service is exposed:

.. Get the token of this ServiceAccount to be used in the request:
+
----
$ token=$(oc whoami -t)
----

.. Run a command similar to the following, using your cluster address to access Elasticsearch through the exposed route:
+
----
curl -tlsv1.2 -v --insecure -H "Authorization: Bearer me3IL_WmD_I_McBUm2uhxIayUKped-H3L1njlRRxPlE" "https://elasticsearch-openshift-logging.apps.<cluster-address>.openshift.com/.operations.*/_search?size=1" | jq

{
  "took": 49,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  ....
----

